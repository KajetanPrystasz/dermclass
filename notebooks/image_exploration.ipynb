{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dermclass_models.image.config import ImageConfig\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "config = ImageConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # TODO: Change to image size taken from mean from files\n",
    "    image_size=(config.IMG_HEIGHT, config.IMG_WIDTH)\n",
    "    \n",
    "    train_dataset = (keras.preprocessing\n",
    "                     .image_dataset_from_directory(config.DATA_PATH,\n",
    "                                                   validation_split=config.TEST_SIZE,\n",
    "                                                   subset=\"training\",\n",
    "                                                   seed=config.SEED,\n",
    "                                                   image_size=image_size,\n",
    "                                                   shuffle=True))    \n",
    "    validation_dataset = (keras.preprocessing\n",
    "               .image_dataset_from_directory(config.DATA_PATH,\n",
    "                                             validation_split=config.TEST_SIZE,\n",
    "                                             subset=\"validation\",\n",
    "                                             seed=config.SEED,\n",
    "                                             image_size=image_size,\n",
    "                                             shuffle=True))\n",
    "    \n",
    "#     val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "#     test_dataset = validation_dataset.take(val_batches // 5)\n",
    "#     validation_dataset = validation_dataset.skip(val_batches // 5)\n",
    "    \n",
    "    return train_ds, validation_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess():\n",
    "    data_augmentation = keras.Sequential([\n",
    "        keras.layers.experimental.preprocessing.Resizing(config.IMG_HEIGHT, config.IMG_WIDTH),\n",
    "        keras.layers.experimental.preprocessing.Rescaling(1.0 / 224),\n",
    "        keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.experimental.preprocessing.RandomRotation(0.1)])\n",
    "    return data_augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 71 files belonging to 3 classes.\n",
      "Using 57 files for training.\n",
      "Found 71 files belonging to 3 classes.\n",
      "Using 14 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = (config.IMG_HEIGHT, config.IMG_WIDTH, 3)\n",
    "output_dim = len(config.DISEASES)\n",
    "batch_size=64\n",
    "epoch_num=20\n",
    "\n",
    "optimizer = keras.optimizers.Adadelta()\n",
    "loss = \"SparseCategoricalCrossentropy\"\n",
    "metrics = [\"acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(data_augmentation)\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", input_shape=input_dim))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\", input_shape=input_dim))\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.MaxPool2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=output_dim, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train_ds, batch_size=batch_size, epochs=epoch_num, verbose=1, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rn = tf.keras.applications.ResNet50V2()\n",
    "rn.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 4s 2s/step - loss: 7.6236 - acc: 0.0175 - val_loss: 26.1659 - val_acc: 0.0000e+00\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 447ms/step - loss: 7.6497 - acc: 0.0175 - val_loss: 18.3543 - val_acc: 0.0000e+00\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 7.5228 - acc: 0.0000e+00 - val_loss: 15.5974 - val_acc: 0.0000e+00\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 7.4442 - acc: 0.0000e+00 - val_loss: 13.9913 - val_acc: 0.0000e+00\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 7.4396 - acc: 0.0000e+00 - val_loss: 12.9587 - val_acc: 0.0000e+00\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 7.4482 - acc: 0.0175 - val_loss: 12.2426 - val_acc: 0.0000e+00\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 7.2820 - acc: 0.0351 - val_loss: 11.7203 - val_acc: 0.0000e+00\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 440ms/step - loss: 7.2788 - acc: 0.0000e+00 - val_loss: 11.4325 - val_acc: 0.0000e+00\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 7.1381 - acc: 0.0351 - val_loss: 11.3532 - val_acc: 0.0000e+00\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 7.1228 - acc: 0.0175 - val_loss: 11.2056 - val_acc: 0.0000e+00\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 7.0945 - acc: 0.0175 - val_loss: 11.1288 - val_acc: 0.0000e+00\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 7.0167 - acc: 0.0175 - val_loss: 11.1027 - val_acc: 0.0000e+00\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 6.9624 - acc: 0.0351 - val_loss: 11.1568 - val_acc: 0.0000e+00\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 6.9306 - acc: 0.0175 - val_loss: 11.1882 - val_acc: 0.0000e+00\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 6.9119 - acc: 0.0351 - val_loss: 11.2147 - val_acc: 0.0000e+00\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 6.9240 - acc: 0.0175 - val_loss: 11.1946 - val_acc: 0.0000e+00\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 442ms/step - loss: 6.7224 - acc: 0.0351 - val_loss: 11.0991 - val_acc: 0.0000e+00\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 6.6820 - acc: 0.0175 - val_loss: 11.0191 - val_acc: 0.0000e+00\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 441ms/step - loss: 6.6498 - acc: 0.0351 - val_loss: 10.9425 - val_acc: 0.0000e+00\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 6.7035 - acc: 0.0351 - val_loss: 10.8034 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b2b1199848>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = rn.fit(train_ds, batch_size=batch_size, epochs=epoch_num, verbose=1, validation_data=validation_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
